{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install HPAT\n",
    "```bash\n",
    "conda create -n HPAT python=3.6\n",
    "source activate HPAT\n",
    "conda install pandas\n",
    "conda install numba -c numba\n",
    "conda install pyarrow mpich -c conda-forge\n",
    "conda install hpat -c ehsantn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pi Example\n",
    "Let's run a simple python numerical function that calculates Pi using a Monte Carlo method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 4.863769292831421 \n",
      "result: 3.14138024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.14138024"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "    return pi\n",
    "\n",
    "calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the same function with hpat.jit decoration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.8851549625396729 \n",
      "result: 3.1416436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1416436"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hpat\n",
    "\n",
    "@hpat.jit\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "    return pi\n",
    "\n",
    "calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hpat.jit decoration gives the function to HPAT to compile. HPAT generates an efficient binary version which replaces the original function in the python environment. In this case, the HPAT version is ~2.5x faster.\n",
    "\n",
    "However, this function was run on a single core. Let's save this code in `pi.py`and run it on multiple cores using MPI:\n",
    "\n",
    "```bash\n",
    "mpiexec -n 4 python pi.py\n",
    "Execution time: 0.9372961521148682 \n",
    "result: 3.1415531\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mpiexec` launches 4 python processes that run the same python program. HPAT parallelize the decorated function on these processes (using the MPI library for communication). It divides the problem space (`n`) and manages communication between cores. In this case, `np.sum` function requires a reduction. The generated function is scalable and can run on any number of cores (e.g. `mpiexec -n 10000`).\n",
    "\n",
    "HPAT supports threading within a single as well. Let's enable HPAT threading for this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.46541595458984375 \n",
      "result: 3.14165164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.14165164"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpat.multithread_mode = True\n",
    "\n",
    "@hpat.jit\n",
    "def calc_pi(n):\n",
    "    t1 = time.time()\n",
    "    x = 2 * np.random.ranf(n) - 1\n",
    "    y = 2 * np.random.ranf(n) - 1\n",
    "    pi = 4 * np.sum(x**2 + y**2 < 1) / n\n",
    "    print(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\n",
    "    return pi\n",
    "\n",
    "calc_pi(2 * 10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPAT can compile a subset of Python which includes Pandas and Numpy operations. See HPAT documentation [here](https://intellabs.github.io/hpat/). HPAT is built on top of Numba, which means Numba's restrictions apply as well. See Numba's documentation [here](http://numba.pydata.org/numba-doc/latest/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Parallelization\n",
    "HPAT parallelizes programs automatically based on the map-reduce parallel pattern. Put simply, this means the compiler analyzes the program to determine whether each array should be distributed or not.\n",
    "\n",
    "To demonstrate parallelization, let's use a simple example. First generate some random number data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(\"data.h5\", \"w\")\n",
    "n = 16\n",
    "f.create_dataset('A', data=np.random.ranf(n))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example HPAT code that reads this data and sums the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.022310532208113\n"
     ]
    }
   ],
   "source": [
    "@hpat.jit\n",
    "def example_1D():\n",
    "    f = h5py.File(\"data.h5\", \"r\")\n",
    "    A = f['A'][:]\n",
    "    return np.sum(A)\n",
    "\n",
    "r = example_1D()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array A is the output of an I/O operation and is input to np.sum. Based on semantics of I/O and np.sum, HPAT determines that A can be distributed since I/O can output a distributed array and np.sum can take a distributed array as input. In map-reduce terminology, A is output of a map operator and is input to a reduce operator. Hence, HPAT distributes A and all operations associated with A (i.e. I/O and np.sum).\n",
    "\n",
    "#### Distribution Report\n",
    "The distributions found by HPAT can be printed using the hpat.distribution_report() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array distributions:\n",
      "   $A.688               1D_Block\n",
      "\n",
      "Parfor distributions:\n",
      "   18                   1D_Block\n"
     ]
    }
   ],
   "source": [
    "hpat.distribution_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report suggests that the function has an array that is distributed in 1D_Block fashion. The variable name is renamed from A to $A.23 through the optimization passes. The report also suggests that there is a parfor (data-parallel for loop) that is \"1D_Block\" distributed.\n",
    "\n",
    "Arrays are distributed in one-dimensional block (1D_Block) manner among processors. This means that processors own equal chunks of each distributed array (except possibly the last processor). Multi-dimensional arrays are distributed along their first dimension by default. For example, chunks of rows are distributed for a 2D matrix. The figure below illustrates the distribution of a 9-element one-dimensional Numpy array, as well as a 9 by 2 array, on three processors. \n",
    "<img src=\"https://intellabs.github.io/hpat/_build/html/_images/dist.jpg\" width=\"35%\">\n",
    "HPAT replicates the arrays that are not distributed. This is called REP distribution for consistency.\n",
    "\n",
    "Checking the distribution report is generally use for ensuring that the function is parallelized as expected. However, HPAT is able to fuse operations and eliminate unused arrays. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Array distributions:\n",
      "\n",
      "Parfor distributions:\n",
      "   22                   1D_Block\n"
     ]
    }
   ],
   "source": [
    "@hpat.jit\n",
    "def example_elim():\n",
    "    A = np.arange(10)\n",
    "    return A.sum()\n",
    "\n",
    "r = example_elim()\n",
    "print(r)\n",
    "hpat.distribution_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the parfor for `arange` and `sum` are fused, and the intermediate array `A` is eliminated. Hence, the program has no arrays left after optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
